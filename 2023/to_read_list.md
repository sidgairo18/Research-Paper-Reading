# Paper Reading List (2023)

(This can be a running list possibly Topic-wise, that can run across years)

## Representation Learning

1. [Matryoshka Representation Learning (NeurIPS 2022)](https://arxiv.org/abs/2205.13147) :red_square:
2. [Image as Set of Points (ICLR 2023, top 5%)](https://arxiv.org/abs/2303.01494) Comments: visual representation learning using Context Clusters. :red_square:

## Object Centric Learning
1. [Bridging the Gap to Real-World Object-Centric Learning (ICLR 2023)](https://arxiv.org/abs/2209.14860) :red_square:
2. [Sequential Attend, Infer, Repeat: Generative Modelling of Moving Objects (NeurIPS 2018)](https://arxiv.org/abs/1806.01794) :red_square:
3. [Attend, Infer, Repeat: Fast Scene Understanding with Generative Models](https://arxiv.org/abs/1603.08575) :red_square:
4. [GENESIS: Generative Scene Inference and Sampling with Object-Centric Latent Representations (ICLR 2020)](https://arxiv.org/abs/1907.13052) :red_square:
5. [MONet: Unsupervised Scene Decomposition and Representation](https://arxiv.org/abs/1901.11390) :red_square:
6. [Multi-Object Representation Learning with Iterative Variational Inference](https://arxiv.org/abs/1903.00450) :red_square:
7. [Matrix Capsules with EM Routing (ICLR 2018)](https://openreview.net/pdf?id=HJWLfGWRb) :red_square:
8. [Dynamic Routing Between Capsules (NeurIPS 2017)](https://proceedings.neurips.cc/paper/2017/file/2cad8fa47bbef282badbb8de5374b894-Paper.pdf) :red_square:
9. [Object-Centric Slot Diffusion (2023) ] (https://arxiv.org/abs/2303.10834) :red_square:
10. [Simple Unsupervised Object-Centric Learning for Complex and Naturalistic Videos (2022)](https://arxiv.org/abs/2205.14065) :red_square:
11. [UNSUPERVISED SEMANTIC SEGMENTATION WITH SELF-SUPERVISED OBJECT-CENTRIC REPRESENTATIONS](https://arxiv.org/pdf/2207.05027.pdf) :red_square:
12. [RELATIVE REPRESENTATIONS ENABLE ZERO-SHOT LATENT SPACE COMMUNICATION](https://arxiv.org/pdf/2209.15430.pdf) :red_square:
13. [Object-Centric Slot Diffusion](https://arxiv.org/pdf/2303.10834.pdf)

## Self-Supervised Learning

## Object Tracking

## XAI

1. [Donâ€™t Judge an Object by Its Context: Learning to Overcome Contextual Bias (CVPR 2020)](https://arxiv.org/abs/2001.03152) :red_square:
2. [Quantifying Attention Flow in Transformers](https://arxiv.org/pdf/2005.00928.pdf) :red_square:
3. [Transformer Interpretability Beyond Attention Visualization](https://arxiv.org/pdf/2012.09838.pdf) :red_square:
4. [Generic Attention-model Explainability for Interpreting Bi-Modal and Encoder-Decoder Transformers](https://openaccess.thecvf.com/content/ICCV2021/papers/Chefer_Generic_Attention-Model_Explainability_for_Interpreting_Bi-Modal_and_Encoder-Decoder_Transformers_ICCV_2021_paper.pdf) :red_square:
5. [Convolutional Dynamic Alignment Networks for Interpretable Classifications](https://arxiv.org/abs/2104.00032) :red_square:
6. [B-cos Networks: Alignment is All We Need for Interpretability](https://arxiv.org/abs/2205.10268) :red_square:
7. [HOLISTICALLY EXPLAINABLE VISION TRANSFORMERS](https://arxiv.org/pdf/2301.08669.pdf) :red_square:
8. [Towards Better Understanding Attribution Methods](https://openaccess.thecvf.com/content/CVPR2022/papers/Rao_Towards_Better_Understanding_Attribution_Methods_CVPR_2022_paper.pdf) :red_square:
9. [CAM: Learning Deep Features for Discriminative Localization](https://arxiv.org/abs/1512.04150) :red_square:
10. [Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization](https://arxiv.org/abs/1610.02391) :red_square:
11. [Grad-CAM++: Improved Visual Explanations for Deep Convolutional Networks](https://arxiv.org/abs/1710.11063) :red_square:

## Vision Language Models
1. [Learning Open-vocabulary Semantic Segmentation Models From Natural Language Supervision](https://arxiv.org/abs/2301.09121) :red_square:
2. [CLIP Paper: Learning Transferable Visual Models From Natural Language Supervision](https://arxiv.org/abs/2103.00020) :red_square:
3. [GroupViT: Semantic Segmentation Emerges from Text Supervision](https://arxiv.org/abs/2202.11094) :red_square:

## Miscellenous

## Not Classified

### Legend

:green_square: Read
:red_square: Unread
:yellow_square: Should re-read
:black_large_square: Uninteresting / Not relevant anymore
