# Paper Reading List (2023)

(This can be a running list possibly Topic-wise, that can run across years)

## Representation Learning

1. [Matryoshka Representation Learning (NeurIPS 2022)](https://arxiv.org/abs/2205.13147) :red_square:
2. [Image as Set of Points (ICLR 2023, top 5%)](https://arxiv.org/abs/2303.01494) Comments: visual representation learning using Context Clusters. :red_square:

## Object Centric Learning
1. [Bridging the Gap to Real-World Object-Centric Learning (ICLR 2023)](https://arxiv.org/abs/2209.14860) :red_square:
2. [Sequential Attend, Infer, Repeat: Generative Modelling of Moving Objects (NeurIPS 2018)](https://arxiv.org/abs/1806.01794) :red_square:
3. [Attend, Infer, Repeat: Fast Scene Understanding with Generative Models](https://arxiv.org/abs/1603.08575) :red_square:
4. [GENESIS: Generative Scene Inference and Sampling with Object-Centric Latent Representations (ICLR 2020)](https://arxiv.org/abs/1907.13052) :red_square:
5. [MONet: Unsupervised Scene Decomposition and Representation](https://arxiv.org/abs/1901.11390) :red_square:
6. [Multi-Object Representation Learning with Iterative Variational Inference](https://arxiv.org/abs/1903.00450) :red_square:
7. [Matrix Capsules with EM Routing (ICLR 2018)](https://openreview.net/pdf?id=HJWLfGWRb) :red_square:
8. [Dynamic Routing Between Capsules (NeurIPS 2017)](https://proceedings.neurips.cc/paper/2017/file/2cad8fa47bbef282badbb8de5374b894-Paper.pdf) :red_square:
9. [Object-Centric Slot Diffusion (2023) ] (https://arxiv.org/abs/2303.10834) :red_square:
10. [Simple Unsupervised Object-Centric Learning for Complex and Naturalistic Videos (2022)](https://arxiv.org/abs/2205.14065) :red_square:
11. [UNSUPERVISED SEMANTIC SEGMENTATION WITH SELF-SUPERVISED OBJECT-CENTRIC REPRESENTATIONS](https://arxiv.org/pdf/2207.05027.pdf) :red_square:
12. [RELATIVE REPRESENTATIONS ENABLE ZERO-SHOT LATENT SPACE COMMUNICATION](https://arxiv.org/pdf/2209.15430.pdf) :red_square:
13. [Object-Centric Slot Diffusion](https://arxiv.org/pdf/2303.10834.pdf)

## Self-Supervised Learning
1. [Deep Spectral Methods: A Surprisingly Strong Baseline for Unsupervised Semantic Segmentation and Localization](https://arxiv.org/pdf/2205.07839.pdf) :red_square:
2. [DINOv1: Emerging Properties in Self-Supervised Vision Transformers](https://arxiv.org/pdf/2104.14294.pdf) :red_square:
3. [DINOv2: Learning Robust Visual Features without Supervision](https://arxiv.org/pdf/2304.07193.pdf) :red_square:
4. [Cut and Learn for Unsupervised Object Detection and Instance Segmentation](https://arxiv.org/pdf/2301.11320.pdf) :red_square:
5. [Unsupervised Semantic Segmentation with Self-supervised Object-centric Representations](https://arxiv.org/pdf/2207.05027.pdf) :red_square:
6. 

## Weakly Supervised Learning
1. [SemFormer: Semantic Guided Activation Transformer for Weakly Supervised Semantic Segmentation](https://arxiv.org/pdf/2210.14618.pdf) :red_square:
2. [SLAMs: Semantic Learning based Activation Map for Weakly Supervised Semantic Segmentation](https://arxiv.org/pdf/2210.12417.pdf) :red_square:
3. [Pointly-Supervised Instance Segmentation](https://openaccess.thecvf.com/content/CVPR2022/papers/Cheng_Pointly-Supervised_Instance_Segmentation_CVPR_2022_paper.pdf) :red_square:
4. [Weakly Supervised Semantic Segmentation using Out-of-Distribution Data](https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Weakly_Supervised_Semantic_Segmentation_Using_Out-of-Distribution_Data_CVPR_2022_paper.pdf) :red_sqauare:
5. [Towards Noiseless Object Contours for Weakly Supervised Semantic Segmentation](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Towards_Noiseless_Object_Contours_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2022_paper.pdf) :red_square:
6. [Simple Does It: Weakly Supervised Instance and Semantic Segmentation](https://arxiv.org/pdf/1603.07485.pdf) :red_square:
7. [Mining Cross-Image Semantics for Weakly Supervised Semantic Segmentation](https://arxiv.org/pdf/2007.01947.pdf) :red_square:
8. [Self-supervised Equivariant Attention Mechanism for Weakly Supervised Semantic Segmentation](https://arxiv.org/pdf/2004.04581.pdf) :red_square:
9. [Pseudo-mask Matters in Weakly-supervised Semantic Segmentation](https://arxiv.org/pdf/2108.12995.pdf) :red_square:
10. [Weakly-Supervised Semantic Segmentation via Sub-category Exploration](https://arxiv.org/pdf/2008.01183.pdf) :red_square:
11. 

## Image Segmentation
1. [Normalized Cuts and Image Segmentation](https://people.eecs.berkeley.edu/~malik/papers/SM-ncut.pdf) :red_square:
    1.1 [Normalized Graph Cuts PPT](http://www.sci.utah.edu/~gerig/CS7960-S2010/handouts/Normalized%20Graph%20cuts.pdf) :red_square:


## Object Tracking

## XAI

1. [Donâ€™t Judge an Object by Its Context: Learning to Overcome Contextual Bias (CVPR 2020)](https://arxiv.org/abs/2001.03152) :red_square:
2. [Quantifying Attention Flow in Transformers](https://arxiv.org/pdf/2005.00928.pdf) :red_square:
3. [Transformer Interpretability Beyond Attention Visualization](https://arxiv.org/pdf/2012.09838.pdf) :red_square:
4. [Generic Attention-model Explainability for Interpreting Bi-Modal and Encoder-Decoder Transformers](https://openaccess.thecvf.com/content/ICCV2021/papers/Chefer_Generic_Attention-Model_Explainability_for_Interpreting_Bi-Modal_and_Encoder-Decoder_Transformers_ICCV_2021_paper.pdf) :red_square:
5. [Convolutional Dynamic Alignment Networks for Interpretable Classifications](https://arxiv.org/abs/2104.00032) :red_square:
6. [B-cos Networks: Alignment is All We Need for Interpretability](https://arxiv.org/abs/2205.10268) :red_square:
7. [HOLISTICALLY EXPLAINABLE VISION TRANSFORMERS](https://arxiv.org/pdf/2301.08669.pdf) :red_square:
8. [Towards Better Understanding Attribution Methods](https://openaccess.thecvf.com/content/CVPR2022/papers/Rao_Towards_Better_Understanding_Attribution_Methods_CVPR_2022_paper.pdf) :red_square:
9. [CAM: Learning Deep Features for Discriminative Localization](https://arxiv.org/abs/1512.04150) :red_square:
10. [Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization](https://arxiv.org/abs/1610.02391) :red_square:
11. [Grad-CAM++: Improved Visual Explanations for Deep Convolutional Networks](https://arxiv.org/abs/1710.11063) :red_square:
12. [Right for the Right Concept: Revising Neuro-Symbolic Concepts by Interacting with their Explanations](https://openaccess.thecvf.com/content/CVPR2021/papers/Stammer_Right_for_the_Right_Concept_Revising_Neuro-Symbolic_Concepts_by_Interacting_CVPR_2021_paper.pdf) :red_square
13. [Interpretable Explanations of Black Boxes by Meaningful Perturbation](https://arxiv.org/pdf/1704.03296.pdf) :red_square:

## Vision Language Models
1. [Learning Open-vocabulary Semantic Segmentation Models From Natural Language Supervision](https://arxiv.org/abs/2301.09121) :red_square:
2. [CLIP Paper: Learning Transferable Visual Models From Natural Language Supervision](https://arxiv.org/abs/2103.00020) :red_square:
3. [GroupViT: Semantic Segmentation Emerges from Text Supervision](https://arxiv.org/abs/2202.11094) :red_square:
4. [Learning Visual Representations via Language-Guided Sampling](https://arxiv.org/pdf/2302.12248.pdf) :red_square:
5. [DenseCLIP: Language-Guided Dense Prediction with Context-Aware Prompting](https://arxiv.org/pdf/2112.01518.pdf) :red_square:
6.

## Miscellenous
1. [Early Convolutions Help Transformers See Better](https://arxiv.org/pdf/2106.14881.pdf) :red_square:
2. [Visualizing and Understanding Convolutional Networks](https://arxiv.org/pdf/1311.2901.pdf) :red_square:
3. [Look and Think Twice: Capturing Top-Down Visual Attention with Feedback Convolutional Neural Networks](https://openaccess.thecvf.com/content_iccv_2015/papers/Cao_Look_and_Think_ICCV_2015_paper.pdf) :red_square:

## Not Classified

## Learning Notes
1. [Truncated Normal](https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf) :red_square:

### Legend

:green_square: Read
:red_square: Unread
:yellow_square: Should re-read
:black_large_square: Uninteresting / Not relevant anymore
