# Paper Reading List (2023)

(This can be a running list possibly Topic-wise, that can run across years)

## Representation Learning

1. [Matryoshka Representation Learning (NeurIPS 2022)](https://arxiv.org/abs/2205.13147) :red_square:
2. [Image as Set of Points (ICLR 2023, top 5%)](https://arxiv.org/abs/2303.01494) Comments: visual representation learning using Context Clusters. :red_square:

## Object Detection, Localization, Tracking, and similar
1. [DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection](https://arxiv.org/pdf/2203.03605.pdf) :red_square:
2. [DETR: End-to-End Object Detection with Transformers](https://arxiv.org/pdf/2005.12872.pdf) :red_square:
3. [DETR++: Taming Your Multi-Scale Detection Transformer](https://arxiv.org/pdf/2206.02977.pdf) :red_square:
4. [Deformable DETR: Deformable Transformers for End-to-End Object Detection](https://arxiv.org/abs/2010.04159) :red_square: 
5. [Mask DINO: Towards A Unified Transformer-based Framework for Object Detection and Segmentation](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Mask_DINO_Towards_a_Unified_Transformer-Based_Framework_for_Object_Detection_CVPR_2023_paper.pdf) :red_square:

## Object Centric Learning
1. [Bridging the Gap to Real-World Object-Centric Learning (ICLR 2023)](https://arxiv.org/abs/2209.14860) :red_square:
2. [Sequential Attend, Infer, Repeat: Generative Modelling of Moving Objects (NeurIPS 2018)](https://arxiv.org/abs/1806.01794) :red_square:
3. [Attend, Infer, Repeat: Fast Scene Understanding with Generative Models](https://arxiv.org/abs/1603.08575) :red_square:
4. [GENESIS: Generative Scene Inference and Sampling with Object-Centric Latent Representations (ICLR 2020)](https://arxiv.org/abs/1907.13052) :red_square:
5. [MONet: Unsupervised Scene Decomposition and Representation](https://arxiv.org/abs/1901.11390) :red_square:
6. [Multi-Object Representation Learning with Iterative Variational Inference](https://arxiv.org/abs/1903.00450) :red_square:
7. [Matrix Capsules with EM Routing (ICLR 2018)](https://openreview.net/pdf?id=HJWLfGWRb) :red_square:
8. [Dynamic Routing Between Capsules (NeurIPS 2017)](https://proceedings.neurips.cc/paper/2017/file/2cad8fa47bbef282badbb8de5374b894-Paper.pdf) :red_square:
9. [Object-Centric Slot Diffusion (2023) ] (https://arxiv.org/abs/2303.10834) :red_square:
10. [Simple Unsupervised Object-Centric Learning for Complex and Naturalistic Videos (2022)](https://arxiv.org/abs/2205.14065) :red_square:
11. [UNSUPERVISED SEMANTIC SEGMENTATION WITH SELF-SUPERVISED OBJECT-CENTRIC REPRESENTATIONS](https://arxiv.org/pdf/2207.05027.pdf) :red_square:
12. [RELATIVE REPRESENTATIONS ENABLE ZERO-SHOT LATENT SPACE COMMUNICATION](https://arxiv.org/pdf/2209.15430.pdf) :red_square:
13. [Object-Centric Representation Learning with Generative Spatial-Temporal Factorization](https://arxiv.org/pdf/2111.05393.pdf) :red_square:
14. [ILLITERATE DALL-E LEARNS TO COMPOSE](https://arxiv.org/pdf/2110.11405.pdf) :red_square:
15. [Shepherding Slots to Objects: Towards Stable and Robust Object-Centric Learning](https://arxiv.org/pdf/2303.17842.pdf) :red_square:
16. [OBJECT REPRESENTATIONS AS FIXED POINTS: TRAINING ITERATIVE INFERENCE ALGORITHMS WITH IMPLICIT DIFFERENTIATION](https://openreview.net/pdf?id=rV3Gon4dD-5) :red_square:
17. [Object Discovery from Motion-Guided Tokens](https://openaccess.thecvf.com/content/CVPR2023/papers/Bao_Object_Discovery_From_Motion-Guided_Tokens_CVPR_2023_paper.pdf) :red_square:
18. [Unsupervised Object Localization: Observing the Background to Discover Objects](https://openaccess.thecvf.com/content/CVPR2023/papers/Simeoni_Unsupervised_Object_Localization_Observing_the_Background_To_Discover_Objects_CVPR_2023_paper.pdf) :red_square:

## Self-Supervised Learning (Vision)
1. [Deep Spectral Methods: A Surprisingly Strong Baseline for Unsupervised Semantic Segmentation and Localization](https://arxiv.org/pdf/2205.07839.pdf) :red_square:
2. [DINOv1: Emerging Properties in Self-Supervised Vision Transformers](https://arxiv.org/pdf/2104.14294.pdf) :red_square:
3. [DINOv2: Learning Robust Visual Features without Supervision](https://arxiv.org/pdf/2304.07193.pdf) :red_square:
4. [Cut and Learn for Unsupervised Object Detection and Instance Segmentation](https://arxiv.org/pdf/2301.11320.pdf) :red_square:
5. [Unsupervised Semantic Segmentation with Self-supervised Object-centric Representations](https://arxiv.org/pdf/2207.05027.pdf) :red_square:
6. [Unsupervised Part Discovery from Contrastive Reconstruction](https://proceedings.neurips.cc/paper/2021/file/ec8ce6abb3e952a85b8551ba726a1227-Paper.pdf) :red_square: 
7. [WHAT DO SELF-SUPERVISED VISION TRANSFORMERS LEARN?](https://arxiv.org/pdf/2305.00729.pdf) :red_square:
[OPEN REVIEW DISCUSSION OF ABOVE](https://openreview.net/forum?id=azCKuYyS74)
8. [Localizing Objects with Self-Supervised Transformers and no Labels](https://arxiv.org/pdf/2109.14279.pdf) :red_square:
9. [ResMLP: Feedforward networks for image classification with data-efficient training](https://arxiv.org/pdf/2105.03404.pdf) :red_square:
10. [Invariant Information Clustering for Unsupervised Image Classification and Segmentation](https://arxiv.org/pdf/1807.06653.pdf) :red_square:
11. [Self-Supervised Learning from Images with a Joint-Embedding Predictive Architecture](https://openaccess.thecvf.com/content/CVPR2023/papers/Assran_Self-Supervised_Learning_From_Images_With_a_Joint-Embedding_Predictive_Architecture_CVPR_2023_paper.pdf) :red_square:
12. [Understanding Masked Image Modeling via Learning Occlusion Invariant Feature](https://openaccess.thecvf.com/content/CVPR2023/papers/Kong_Understanding_Masked_Image_Modeling_via_Learning_Occlusion_Invariant_Feature_CVPR_2023_paper.pdf) :red_square:
13. [Self-supervised AutoFlow](https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_Self-Supervised_AutoFlow_CVPR_2023_paper.pdf) :red_square:
14. [Hard Patches Mining for Masked Image Modeling](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Hard_Patches_Mining_for_Masked_Image_Modeling_CVPR_2023_paper.pdf) :red_square:
15. [Siamese Image Modeling for Self-Supervised Vision Representation Learning](https://openaccess.thecvf.com/content/CVPR2023/papers/Tao_Siamese_Image_Modeling_for_Self-Supervised_Vision_Representation_Learning_CVPR_2023_paper.pdf) :red_square:
16. [Mixed Autoencoder for Self-supervised Visual Representation Learning](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Mixed_Autoencoder_for_Self-Supervised_Visual_Representation_Learning_CVPR_2023_paper.pdf) :red_square:
17. [Coreset Sampling from Open-Set for Fine-Grained Self-Supervised Learning](https://openaccess.thecvf.com/content/CVPR2023/papers/Kim_Coreset_Sampling_From_Open-Set_for_Fine-Grained_Self-Supervised_Learning_CVPR_2023_paper.pdf) :red_square:
18. [Masked Images Are Counterfactual Samples for Robust Fine-tuning](https://openaccess.thecvf.com/content/CVPR2023/papers/Xiao_Masked_Images_Are_Counterfactual_Samples_for_Robust_Fine-Tuning_CVPR_2023_paper.pdf) :red_square:



## Weakly Supervised Learning
1. [SemFormer: Semantic Guided Activation Transformer for Weakly Supervised Semantic Segmentation](https://arxiv.org/pdf/2210.14618.pdf) :red_square:
2. [SLAMs: Semantic Learning based Activation Map for Weakly Supervised Semantic Segmentation](https://arxiv.org/pdf/2210.12417.pdf) :red_square:
3. [Pointly-Supervised Instance Segmentation](https://openaccess.thecvf.com/content/CVPR2022/papers/Cheng_Pointly-Supervised_Instance_Segmentation_CVPR_2022_paper.pdf) :red_square:
4. [Weakly Supervised Semantic Segmentation using Out-of-Distribution Data](https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Weakly_Supervised_Semantic_Segmentation_Using_Out-of-Distribution_Data_CVPR_2022_paper.pdf) :red_sqauare:
5. [Towards Noiseless Object Contours for Weakly Supervised Semantic Segmentation](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Towards_Noiseless_Object_Contours_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2022_paper.pdf) :red_square:
6. [Simple Does It: Weakly Supervised Instance and Semantic Segmentation](https://arxiv.org/pdf/1603.07485.pdf) :red_square:
7. [Mining Cross-Image Semantics for Weakly Supervised Semantic Segmentation](https://arxiv.org/pdf/2007.01947.pdf) :red_square:
8. [Self-supervised Equivariant Attention Mechanism for Weakly Supervised Semantic Segmentation](https://arxiv.org/pdf/2004.04581.pdf) :red_square:
9. [Pseudo-mask Matters in Weakly-supervised Semantic Segmentation](https://arxiv.org/pdf/2108.12995.pdf) :red_square:
10. [Weakly-Supervised Semantic Segmentation via Sub-category Exploration](https://arxiv.org/pdf/2008.01183.pdf) :red_square:
11. 

## Few-Shot Learning
1. [Hypercorrelation Squeeze for Few-Shot Segmentation](https://openaccess.thecvf.com/content/ICCV2021/papers/Min_Hypercorrelation_Squeeze_for_Few-Shot_Segmentation_ICCV_2021_paper.pdf) :red_square:
2. 

## Image Segmentation
1. [Normalized Cuts and Image Segmentation](https://people.eecs.berkeley.edu/~malik/papers/SM-ncut.pdf) :red_square:
    1.1 [Normalized Graph Cuts PPT](http://www.sci.utah.edu/~gerig/CS7960-S2010/handouts/Normalized%20Graph%20cuts.pdf) :red_square:


## Object Tracking

## XAI

1. [Donâ€™t Judge an Object by Its Context: Learning to Overcome Contextual Bias (CVPR 2020)](https://arxiv.org/abs/2001.03152) :red_square:
2. [Quantifying Attention Flow in Transformers](https://arxiv.org/pdf/2005.00928.pdf) :red_square:
3. [Transformer Interpretability Beyond Attention Visualization](https://arxiv.org/pdf/2012.09838.pdf) :red_square:
4. [Generic Attention-model Explainability for Interpreting Bi-Modal and Encoder-Decoder Transformers](https://openaccess.thecvf.com/content/ICCV2021/papers/Chefer_Generic_Attention-Model_Explainability_for_Interpreting_Bi-Modal_and_Encoder-Decoder_Transformers_ICCV_2021_paper.pdf) :red_square:
5. [Convolutional Dynamic Alignment Networks for Interpretable Classifications](https://arxiv.org/abs/2104.00032) :red_square:
6. [B-cos Networks: Alignment is All We Need for Interpretability](https://arxiv.org/abs/2205.10268) :red_square:
7. [HOLISTICALLY EXPLAINABLE VISION TRANSFORMERS](https://arxiv.org/pdf/2301.08669.pdf) :red_square:
8. [Towards Better Understanding Attribution Methods](https://openaccess.thecvf.com/content/CVPR2022/papers/Rao_Towards_Better_Understanding_Attribution_Methods_CVPR_2022_paper.pdf) :red_square:
9. [CAM: Learning Deep Features for Discriminative Localization](https://arxiv.org/abs/1512.04150) :red_square:
10. [Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization](https://arxiv.org/abs/1610.02391) :red_square:
11. [Grad-CAM++: Improved Visual Explanations for Deep Convolutional Networks](https://arxiv.org/abs/1710.11063) :red_square:
12. [Right for the Right Concept: Revising Neuro-Symbolic Concepts by Interacting with their Explanations](https://openaccess.thecvf.com/content/CVPR2021/papers/Stammer_Right_for_the_Right_Concept_Revising_Neuro-Symbolic_Concepts_by_Interacting_CVPR_2021_paper.pdf) :red_square
13. [Interpretable Explanations of Black Boxes by Meaningful Perturbation](https://arxiv.org/pdf/1704.03296.pdf) :red_square:
14. [Fast Axiomatic Attribution for Neural Networks](https://arxiv.org/pdf/2111.07668.pdf) :red_sqare:
15. [This Looks Like That... Does it? Shortcomings of Latent Space Prototype Interpretability in Deep Networks](https://arxiv.org/pdf/2105.02968.pdf) :red_square:
16. [Class Attention Transfer Based Knowledge Distillation](https://openaccess.thecvf.com/content/CVPR2023/papers/Guo_Class_Attention_Transfer_Based_Knowledge_Distillation_CVPR_2023_paper.pdf) :red_square:
17. [CRAFT: Concept Recursive Activation FacTorization for Explainability](https://openaccess.thecvf.com/content/CVPR2023/papers/Fel_CRAFT_Concept_Recursive_Activation_FacTorization_for_Explainability_CVPR_2023_paper.pdf) :red_square:

## Vision Language Models
1. [Learning Open-vocabulary Semantic Segmentation Models From Natural Language Supervision](https://arxiv.org/abs/2301.09121) :red_square:
2. [CLIP Paper: Learning Transferable Visual Models From Natural Language Supervision](https://arxiv.org/abs/2103.00020) :red_square:
3. [GroupViT: Semantic Segmentation Emerges from Text Supervision](https://arxiv.org/abs/2202.11094) :red_square:
4. [Learning Visual Representations via Language-Guided Sampling](https://arxiv.org/pdf/2302.12248.pdf) :red_square:
5. [DenseCLIP: Language-Guided Dense Prediction with Context-Aware Prompting](https://arxiv.org/pdf/2112.01518.pdf) :red_square:
6.

## Language or NLP Papers
1. [IBOT : IMAGE BERT PRE-TRAINING WITH ONLINE TOKENIZER](https://arxiv.org/pdf/2111.07832.pdf) :red_square:

## Generative Models
1. [ImageGPT: Generative Pretraining from Pixels](https://cdn.openai.com/papers/Generative_Pretraining_from_Pixels_V2.pdf) :red_square:

## Miscellenous
1. [Early Convolutions Help Transformers See Better](https://arxiv.org/pdf/2106.14881.pdf) :red_square:
2. [Visualizing and Understanding Convolutional Networks](https://arxiv.org/pdf/1311.2901.pdf) :red_square:
3. [Look and Think Twice: Capturing Top-Down Visual Attention with Feedback Convolutional Neural Networks](https://openaccess.thecvf.com/content_iccv_2015/papers/Cao_Look_and_Think_ICCV_2015_paper.pdf) :red_square:
4. [DeiT III: Revenge of the ViT](https://arxiv.org/abs/2204.07118) :red_square:
5. [Deformable Convolutional Networks](https://openaccess.thecvf.com/content_ICCV_2017/papers/Dai_Deformable_Convolutional_Networks_ICCV_2017_paper.pdf) :red_square:

## Not Classified
1. [Choose Your Weapon: Survival Strategies for Depressed AI Academics](https://arxiv.org/pdf/2304.06035.pdf) :red_square:
2. [SPREADING VECTORS FOR SIMILARITY SEARCH](https://arxiv.org/pdf/1806.03198.pdf) :red_square:
3. [Understanding Imbalanced Semantic Segmentation Through Neural Collapse](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhong_Understanding_Imbalanced_Semantic_Segmentation_Through_Neural_Collapse_CVPR_2023_paper.pdf) :red_square:
4. [NIRVANA: Neural Implicit Representations of Videos with Adaptive Networks and Autoregressive Patch-wise Modeling](https://openaccess.thecvf.com/content/CVPR2023/papers/Maiya_NIRVANA_Neural_Implicit_Representations_of_Videos_With_Adaptive_Networks_and_CVPR_2023_paper.pdf) :red_square:

## Learning Notes
1. [Truncated Normal](https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf) :red_square:

## Additional Resources
1. [Reading for Graduate Students (General by Matt Might)](https://matt.might.net/articles/books-papers-materials-for-graduate-students/) :red_square:

### Legend

:green_square: Read
:red_square: Unread
:yellow_square: Should re-read
:black_large_square: Uninteresting / Not relevant anymore
